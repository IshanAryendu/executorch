# Configuration for basic XNNPACK 8da4w quantization
# Used in apple-perf.yml and android-perf.yml

base:
  model_class: "llama3_2"

model:
  dtype_override: "fp32"
  use_kv_cache: true
  use_sdpa_with_kv_cache: true

export:
  max_seq_length: 128
  max_context_length: 128

quantization:
  qmode: "8da4w"
  group_size: 32
  embedding_quantize: "8,0"

backend:
  xnnpack:
    enabled: true
    extended_ops: true

debug:
  verbose: false