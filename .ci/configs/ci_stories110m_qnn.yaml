# Configuration for CI test_llama.sh - stories110M with QNN backend

base:
  model_class: "stories110m"
  tokenizer_path: "tokenizer.model"

model:
  dtype_override: "fp32"
  use_kv_cache: true
  enable_dynamic_shape: false

export:
  max_seq_length: 128
  max_context_length: 128

quantization:
  pt2e_quantize: "qnn_16a16w"
  calibration_tasks: ["wikitext"]
  calibration_limit: 1
  calibration_seq_length: 128
  calibration_data: "Once"

backend:
  qnn:
    enabled: true

debug:
  verbose: true